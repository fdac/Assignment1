{
 "metadata": {
  "name": "",
  "signature": "sha256:114cfa3ce162ccc60690a3ccf41282366adea0470ab453cc32d33e88299b251f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests, re, nltk\n",
      "from BeautifulSoup import BeautifulStoneSoup\n",
      "from nltk import clean_html\n",
      "from collections import Counter\n",
      "import operator\n",
      "\n",
      "# we may not care about the usage of stop words\n",
      "nltk .download ('stopwords')\n",
      "stop_words = nltk.corpus.stopwords.words('english') + [\n",
      " 'ut', '\\'re','.', ',', '--', '\\'s', '?', ')', '(', ':', '\\'',\n",
      " '\\\"', '-', '}', '{', '&', '|', u'\\u2014' ]\n",
      "\n",
      "# We most likely would like to remove html markup\n",
      "def cleanHtml (html):\n",
      "    return BeautifulStoneSoup(clean_html(html),\n",
      "                convertEntities=BeautifulStoneSoup.HTML_ENTITIES).contents[0]\n",
      "\n",
      "# We also want to remove special characters, quotes, etc. from each word\n",
      "def cleanWord (w):\n",
      "    # r in r'[.,\"\\']' stands for regular expression\n",
      "    # any character between the brackets [] is to be removed \n",
      "    return re.sub(r'[.,\"\\.]', \"\", w)\n",
      "       \n",
      "# define a function to get text/clean/calculate frequency\n",
      "def get_wf (URL):\n",
      "    # first get the web page\n",
      "    r = requests .get(URL)\n",
      "    \n",
      "    # Now clean\n",
      "    # remove html markup\n",
      "    t = cleanHtml (r .text) .lower()\n",
      "    \n",
      "    # split string into an array of words using any sequence of spaces \"\\s+\" \n",
      "    wds = re .split('\\s+',t)\n",
      "    \n",
      "    # remove periods, commas, etc stuck to the edges of words\n",
      "    for i in range(len(wds)):\n",
      "        wds [i] = cleanWord (wds [i])\n",
      "    \n",
      "    # If satisfied with results, lets go to the next step: calculate frequencies\n",
      "    # We can write a loop to create a dictionary, but \n",
      "    # there is a special function for everything in python\n",
      "    # in particular for counting frequencies (like function table() in R)\n",
      "    wf = Counter (wds)\n",
      "    \n",
      "    # Remove stop words from the dictionary wf\n",
      "    for k in stop_words:\n",
      "        wf. pop(k, None)\n",
      "        \n",
      "    #how many regular words in the document?\n",
      "    tw = 0\n",
      "    for w in wf:\n",
      "       tw += wf[w] \n",
      "        \n",
      "    \n",
      "    # Get ordered list\n",
      "    wfs = sorted (wf .iteritems(), key = operator.itemgetter(1), reverse=True)\n",
      "    ml = min(len(wfs),15)\n",
      "\n",
      "    #Reverse the list because barh plots items from the bottom\n",
      "    return (wfs [ 1:ml ] [::-1], tw)\n",
      "        \n",
      "# Now populate two lists    \n",
      "(wf_ee, tw_ee) = get_wf('http://www.gutenberg.org/cache/epub/74/pg74.txt')\n",
      "(wf_bu, tw_bu) = get_wf('http://www.gutenberg.org/ebooks/76.txt.utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot the results: are there striking differences in language?\n",
      "import numpy as np\n",
      "import pylab\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "%matplotlib inline\n",
      "def plotTwoLists (wf_ee, wf_bu, title):\n",
      "    f = plt.figure (figsize=(10, 6))\n",
      "    # this is painfully tedious....\n",
      "    f .suptitle (title, fontsize=20)\n",
      "    ax = f.add_subplot(111)\n",
      "    ax .spines ['top'] .set_color ('none')\n",
      "    ax .spines ['bottom'] .set_color ('none')\n",
      "    ax .spines ['left'] .set_color ('none')\n",
      "    ax .spines ['right'] .set_color ('none')\n",
      "    ax .tick_params (labelcolor='w', top='off', bottom='off', left='off', right='off', labelsize=20)\n",
      "\n",
      "    # Create two subplots, this is the first one\n",
      "    ax1 = f .add_subplot (121)\n",
      "    plt .subplots_adjust (wspace=.5)\n",
      "\n",
      "    pos = np .arange (len(wf_ee)+1) \n",
      "    ax1 .tick_params (axis='both', which='major', labelsize=14)\n",
      "    pylab .yticks (pos, [ x [0] for x in wf_ee ])\n",
      "    ax1 .barh (range(len(wf_ee)), [ x [1] for x in wf_ee ], align='center')\n",
      "\n",
      "    ax2 = f .add_subplot (122)\n",
      "    ax2 .tick_params (axis='both', which='major', labelsize=14)\n",
      "    pos = np .arange (len(wf_bu)+1) \n",
      "    pylab .yticks (pos, [ x [0] for x in wf_bu ])\n",
      "    ax2 .barh (range (len(wf_bu)), [ x [1] for x in wf_bu ], align='center')\n",
      "\n",
      "plotTwoLists (wf_ee, wf_bu, 'Most Frequent words frequencies between two works of a single author (Mark Twain')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}