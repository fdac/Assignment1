{
 "metadata": {
  "name": "",
  "signature": "sha256:2186469fb68552280d08f513594cb78a0430889df36827c5a60f0296a969c01a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Written text as operational data\n",
      "\n",
      "Written text is one type of data\n",
      "\n",
      "### Why people write?\n",
      "\n",
      " - To communicate: their thoughts, feelings, urgency, needs, information\n",
      "\n",
      "### Why people communicate?\n",
      "\n",
      "1. To express emotions\n",
      "1. To share information\n",
      "1. To enable or elicit an action\n",
      "1. ...\n",
      "\n",
      "### We will use written text for the purpose other than \n",
      "1. To experience emotion\n",
      "1. To learn something the author intended us to learn\n",
      "1. To do what the author intended us to do\n",
      "\n",
      "### Instead, we will use written text to recognize who wrote it\n",
      " - By calculating and comparing word frequencies in written documents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Example 1. Dictionaries in python (associative arrays)\n",
      "\n",
      "Plot the frequency distribution of words on a web page."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<div\t51\n",
        "</div>\t38\n",
        "of\t33\n",
        "the\t23\n",
        "and\t20\n",
        "<a\t17\n",
        "</ul>\t16\n",
        "Computer\t16\n",
        "Engineering\t15\n",
        "=\t14\n",
        "</li>\t14\n",
        "in\t12\n",
        "a\t11\n",
        "var\t11\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Example 2\n",
      "\n",
      "Lots of markup in the output, lets remove it --- \n",
      "\n",
      "use BeautifulSoup and nltk modules and practice some regular expressions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests, re, nltk\n",
      "from BeautifulSoup import BeautifulStoneSoup\n",
      "from nltk import clean_html\n",
      "from collections import Counter\n",
      "import operator\n",
      "\n",
      "# we may not care about the usage of stop words\n",
      "nltk .download ('stopwords')\n",
      "stop_words = nltk.corpus.stopwords.words('english') + [\n",
      " 'ut', '\\'re','.', ',', '--', '\\'s', '?', ')', '(', ':', '\\'',\n",
      " '\\\"', '-', '}', '{', '&', '|', u'\\u2014' ]\n",
      "\n",
      "# We most likely would like to remove html markup\n",
      "def cleanHtml (html):\n",
      "    return BeautifulStoneSoup(clean_html(html),\n",
      "                convertEntities=BeautifulStoneSoup.HTML_ENTITIES).contents[0]\n",
      "\n",
      "# We also want to remove special characters, quotes, etc. from each word\n",
      "def cleanWord (w):\n",
      "    # r in r'[.,\"\\']' stands for regular expression\n",
      "    # any character between the brackets [] is to be removed \n",
      "    return re.sub(r'[.,\"\\.]', \"\", w)\n",
      "       \n",
      "# define a function to get text/clean/calculate frequency\n",
      "def get_wf (URL):\n",
      "    # first get the web page\n",
      "    r = requests .get(URL)\n",
      "    \n",
      "    # Now clean\n",
      "    # remove html markup\n",
      "    t = cleanHtml (r .text) .lower()\n",
      "    \n",
      "    # split string into an array of words using any sequence of spaces \"\\s+\" \n",
      "    wds = re .split('\\s+',t)\n",
      "    \n",
      "    # remove periods, commas, etc stuck to the edges of words\n",
      "    for i in range(len(wds)):\n",
      "        wds [i] = cleanWord (wds [i])\n",
      "    \n",
      "    # If satisfied with results, lets go to the next step: calculate frequencies\n",
      "    # We can write a loop to create a dictionary, but \n",
      "    # there is a special function for everything in python\n",
      "    # in particular for counting frequencies (like function table() in R)\n",
      "    wf = Counter (wds)\n",
      "    \n",
      "    # Remove stop words from the dictionary wf\n",
      "    for k in stop_words:\n",
      "        wf. pop(k, None)\n",
      "    \n",
      "    # Get ordered list\n",
      "    wfs = sorted (wf .iteritems(), key = operator.itemgetter(1), reverse=True)\n",
      "    ml = min(len(wfs),15)\n",
      "\n",
      "    #Reverse the list because barh plots items from the bottom\n",
      "    return wfs [ 1:ml ] [::-1]\n",
      "        \n",
      "# Now populate two lists    \n",
      "wf_ee = get_wf('http://eecs.utk.edu')\n",
      "wf_bu = get_wf('http://bus.utk.edu')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package 'stopwords' to /home/cosc/nltk_data...\n",
        "[nltk_data]   Unzipping corpora/stopwords.zip."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot the results: are there striking differences in language?\n",
      "import numpy as np\n",
      "import pylab\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "%matplotlib inline\n",
      "def plotTwoLists (wf_ee, wf_bu, title):\n",
      "    f = plt.figure (figsize=(10, 6))\n",
      "    # this is painfully tedious....\n",
      "    f .suptitle (title, fontsize=20)\n",
      "    ax = f.add_subplot(111)\n",
      "    ax .spines ['top'] .set_color ('none')\n",
      "    ax .spines ['bottom'] .set_color ('none')\n",
      "    ax .spines ['left'] .set_color ('none')\n",
      "    ax .spines ['right'] .set_color ('none')\n",
      "    ax .tick_params (labelcolor='w', top='off', bottom='off', left='off', right='off', labelsize=20)\n",
      "\n",
      "    # Create two subplots, this is the first one\n",
      "    ax1 = f .add_subplot (121)\n",
      "    plt .subplots_adjust (wspace=.5)\n",
      "\n",
      "    pos = np .arange (len(wf_ee)+1) \n",
      "    ax1 .tick_params (axis='both', which='major', labelsize=14)\n",
      "    pylab .yticks (pos, [ x [0] for x in wf_ee ])\n",
      "    ax1 .barh (range(len(wf_ee)), [ x [1] for x in wf_ee ], align='center')\n",
      "\n",
      "    ax2 = f .add_subplot (122)\n",
      "    ax2 .tick_params (axis='both', which='major', labelsize=14)\n",
      "    pos = np .arange (len(wf_bu)+1) \n",
      "    pylab .yticks (pos, [ x [0] for x in wf_bu ])\n",
      "    ax2 .barh (range (len(wf_bu)), [ x [1] for x in wf_bu ], align='center')\n",
      "\n",
      "plotTwoLists (wf_ee, wf_bu, 'Most Frequent Words From Two Departments')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'wf_ee' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-8e7c70402b26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0max2\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbarh\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwf_bu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwf_bu\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'center'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mplotTwoLists\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwf_ee\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwf_bu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Most Frequent Words From Two Departments'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'wf_ee' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Assignment 1\n",
      "\n",
      "1. Compare word frequencies between two works of a single author.\n",
      "1. Compare word frequencies between works of two authors.\n",
      "1. Are there some words preferred by one author but used less frequently by another author?\n",
      "\n",
      "Project Gutenberg is a good source of for fiction and non-fiction.\n",
      "\n",
      "E.g below are two most popular books from Project Gutenberg:\n",
      "- Pride and Prejudice at http://www.gutenberg.org/ebooks/1342.txt.utf-8\n",
      "- Adventures of Huckleberry Finn at http://www.gutenberg.org/ebooks/76.txt.utf-8"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests, re\n",
      "# re is a module for regular expressions: to detect various combinations of characters\n",
      "import operator\n",
      "\n",
      "# Start from a simple document\n",
      "r = requests.get('http://www.gutenberg.org/ebooks/1342.txt.utf-8')\n",
      "\n",
      "# What comes back includes headers and other HTTP stuff, get just the body of the response\n",
      "t = r.text\n",
      "\n",
      "# obtain words by splitting a string using as separator one or more (+) space/like characters (\\s) \n",
      "wds = re.split('\\s+',t)\n",
      "\n",
      "# now populate a dictionary (wf)\n",
      "wf = {}\n",
      "for w in wds:\n",
      "    if w in wf: wf [w] = wf [w] + 1\n",
      "    else:  wf[w] = 1\n",
      "\n",
      "# dictionaries can not be sorted, so lets get a sorted *list*        \n",
      "wfs = sorted (wf .iteritems(), key = operator .itemgetter (1), reverse=True)   \n",
      "\n",
      "# lets just have no more than 15 words \n",
      "ml = min(len(wfs),15)\n",
      "for i in range(1,ml,1):\n",
      "    print wfs[i][0]+\"\\t\"+str(wfs[i][1])   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "to\t4121\n",
        "of\t3662\n",
        "and\t3309\n",
        "a\t1945\n",
        "her\t1858\n",
        "in\t1813\n",
        "was\t1796\n",
        "I\t1740\n",
        "that\t1419\n",
        "not\t1356\n",
        "she\t1306\n",
        "be\t1209\n",
        "his\t1167\n",
        "had\t1126\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}