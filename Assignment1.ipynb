{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Written text as operational data\n",
      "\n",
      "### Written text is a kind of data\n",
      "\n",
      "## Why people write?\n",
      "\n",
      "### To communicate: their thoughts, feelings\n",
      "\n",
      "## Why people communicate?\n",
      "\n",
      "1. To express emotions\n",
      "1. To share information\n",
      "1. To enable or elicit an action\n",
      "1. ...\n",
      "\n",
      "## We will use written text for purpose other than \n",
      "1. To experience emotion or\n",
      "1. To learn something the author intended us to learn\n",
      "1. To do the author intended us to do\n",
      "\n",
      "## We will use written text to recognize author\n",
      "\n",
      "### By calculating the word frequency in written documents\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Example 1. Dictionaries in python (associative arrays)\n",
      "\n",
      "Plot the frequency distribution of words on a web page."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests, re\n",
      "# re is a module for regular expressions: to detect various combinations of characters\n",
      "import operator\n",
      "\n",
      "# Start from a simple document\n",
      "r = requests .get('http://eecs.utk.edu')\n",
      "t = r.text\n",
      "\n",
      "# obtain words by splitting for one or more (+) space/like characters (\\s) \n",
      "wds = re.split('\\s+',t)\n",
      "\n",
      "# now populate a dictionary (wf)\n",
      "wf = {}\n",
      "for w in wds:\n",
      "    if w in wf: wf [w] = wf [w] + 1\n",
      "    else:  wf[w] = 1\n",
      "# dictionaries can not be sorted, so lets get a sorted *list*        \n",
      "wfs = sorted (wf .iteritems(), key = operator .itemgetter (1), reverse=True)   \n",
      "# lets just have no more than 15 words \n",
      "ml = min(len(wfs),15)\n",
      "for i in range(1,ml,1):\n",
      "    print wfs[i][0]+\"\\t\"+str(wfs[i][1])   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Example 2\n",
      "\n",
      "Lots of markup in the output, lets remove it..\n",
      "\n",
      "Use BeautifulSoup and nltk modules for that"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests, re, nltk\n",
      "from BeautifulSoup import BeautifulStoneSoup\n",
      "from nltk import clean_html\n",
      "from collections import Counter\n",
      "import operator\n",
      "\n",
      "nltk .download ('stopwords')\n",
      "stop_words = nltk.corpus.stopwords.words('english') + [\n",
      " 'ut', '\\'re','.', ',', '--', '\\'s', '?', ')', '(', ':', '\\'',\n",
      " '\\\"', '-', '}', '{', '&', '|', u'\\u2014' ]\n",
      "\n",
      "# define a function to help with removing markup\n",
      "def cleanHtml (html):\n",
      "    return BeautifulStoneSoup(clean_html(html),\n",
      "                convertEntities=BeautifulStoneSoup.HTML_ENTITIES).contents[0]\n",
      "\n",
      "# define a function to get text/clean/calculate frequency\n",
      "def get_wf (URL):\n",
      "    r = requests .get(URL)\n",
      "    t = cleanHtml (r .text) .lower()\n",
      "    # separate string into words using any sequence of spaces \"\\s+\" \n",
      "    wds = re .split('\\s+',t)\n",
      "    #There is a special function for everything in python\n",
      "    # in particular for counting frequencies (like a function table() in R)\n",
      "    wf = Counter (wds)\n",
      "    #Now remove stop words from the dictionary\n",
      "    for k in stop_words:\n",
      "        wf. pop(k, None)\n",
      "    wfs = sorted (wf .iteritems(), key = operator.itemgetter(1), reverse=True)\n",
      "    ml = min(len(wfs),15)\n",
      "    #reverse the list because barh plots from the bottom\n",
      "    return wfs [ 1:ml ] [::-1]\n",
      "        \n",
      "# Now populate two lists    \n",
      "wf_ee = get_wf('http://eecs.utk.edu')\n",
      "wf_bu = get_wf('http://bus.utk.edu')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot the results: are there striking differences in language?\n",
      "import numpy as np\n",
      "import pylab\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "%matplotlib inline\n",
      "f = plt.figure (figsize=(8, 6))\n",
      "# this is painfully tedious....\n",
      "f .suptitle ('Most Frequent Words From Two Departments', fontsize=20)\n",
      "ax = f.add_subplot(111)\n",
      "ax .spines ['top'] .set_color ('none')\n",
      "ax .spines ['bottom'] .set_color ('none')\n",
      "ax .spines ['left'] .set_color ('none')\n",
      "ax .spines ['right'] .set_color ('none')\n",
      "ax .tick_params (labelcolor='w', top='off', bottom='off', left='off', right='off', labelsize=20)\n",
      "\n",
      "# Create two subplots, this is the first one\n",
      "ax1 = f .add_subplot (121)\n",
      "plt .subplots_adjust (wspace=1)\n",
      "\n",
      "pos = np .arange (len(wf_ee)+1) \n",
      "ax1 .tick_params (axis='both', which='major', labelsize=14)\n",
      "pylab .yticks (pos, [ x [0] for x in wf_ee ])\n",
      "ax1 .barh (range(len(wf_ee)), [ x [1] for x in wf_ee ], align='center')\n",
      "\n",
      "ax2 = f .add_subplot (122)\n",
      "ax2 .tick_params (axis='both', which='major', labelsize=14)\n",
      "pos = np .arange (len(wf_bu)+1) \n",
      "pylab .yticks (pos, [ x [0] for x in wf_bu ])\n",
      "ax2 .barh (range (len(wf_bu)), [ x [1] for x in wf_bu ], align='center')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Assignment 1\n",
      "\n",
      "1. Compare word frequencies for two works of a single author.\n",
      "1. Then compare word frequencies between works of two authors.\n",
      "\n",
      "Project Gutenberg is a good source of data.\n",
      "\n",
      "E.g below are two most popular books from Project Gutenberg:\n",
      "- Pride and prejudice at http://www.gutenberg.org/cache/epub/1342/pg1342.txt\n",
      "- Adventures of Huckleberry Finn at http://www.gutenberg.org/cache/epub/76/pg76.txt"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}